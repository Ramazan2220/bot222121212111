#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
üÜö –£–ú–ï–†–ï–ù–ù–´–ô –¢–ï–°–¢: PostgreSQL vs SQLite –ø—Ä–æ–±–ª–µ–º—ã
–î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ–º —á—Ç–æ PostgreSQL —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã SQLite –±–µ–∑ –ø–µ—Ä–µ–≥—Ä—É–∑–∫–∏
"""

import logging
import sys
import time
import threading
import random
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor
from typing import List, Dict, Any

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - [%(threadName)s] - %(message)s'
)
logger = logging.getLogger(__name__)

try:
    from database.db_manager import get_session, init_db
    from database.models import InstagramAccount, PublishTask, WarmupTask, TelegramUser, TaskType, TaskStatus, WarmupStatus
    from sqlalchemy import text
except ImportError as e:
    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")
    sys.exit(1)

class ModeratePostgreSQLTest:
    """–£–º–µ—Ä–µ–Ω–Ω—ã–π —Ç–µ—Å—Ç PostgreSQL vs SQLite"""
    
    def __init__(self):
        self.test_stats = {
            'operations_completed': 0,
            'threads_completed': 0,
            'errors_found': 0,
            'start_time': None,
            'postgresql_advantages': []
        }
        
    def create_test_batch(self, user_base_id: int, batch_size: int = 10) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –±–∞—Ç—á–∞ (–±–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ä–∞–∑–º–µ—Ä)"""
        
        batch_result = {
            'users_created': 0,
            'accounts_created': 0,
            'tasks_created': 0,
            'time_taken': 0,
            'errors': []
        }
        
        start_time = time.time()
        
        try:
            with get_session() as session:
                for i in range(batch_size):
                    user_id = user_base_id + i
                    
                    # –°–æ–∑–¥–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                    telegram_user = TelegramUser(
                        telegram_id=user_id,
                        username=f"pg_test_{user_id}",
                        first_name=f"PostgreSQL {i}",
                        last_name="Test",
                        is_active=True
                    )
                    session.merge(telegram_user)
                    batch_result['users_created'] += 1
                    
                    # –°–æ–∑–¥–∞–µ–º –∞–∫–∫–∞—É–Ω—Ç—ã
                    for j in range(2):  # –ü–æ 2 –∞–∫–∫–∞—É–Ω—Ç–∞
                        account = InstagramAccount(
                            username=f"pg_{user_id}_{j}_{random.randint(1000, 9999)}",
                            password=f"pgpass_{user_id}_{j}",
                            email=f"pg_{user_id}_{j}@postgres.test",
                            user_id=user_id,
                            is_active=True,
                            full_name=f"PostgreSQL Account {user_id}-{j}",
                            biography=f"PostgreSQL test account"
                        )
                        session.add(account)
                        batch_result['accounts_created'] += 1
                        
                    session.flush()
                    
                    # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏
                    user_accounts = session.query(InstagramAccount).filter_by(user_id=user_id).all()
                    
                    for account in user_accounts:
                        # PublishTask (–ø—Ä–æ–±–ª–µ–º–Ω–∞—è –≤ SQLite)
                        publish_task = PublishTask(
                            account_id=account.id,
                            user_id=user_id,
                            task_type=TaskType.VIDEO,
                            caption=f"PostgreSQL test video from user {user_id}",
                            scheduled_time=datetime.now() + timedelta(hours=random.randint(1, 12)),
                            status=TaskStatus.PENDING
                        )
                        session.add(publish_task)
                        batch_result['tasks_created'] += 1
                        
                        # WarmupTask (–ø—Ä–æ–±–ª–µ–º–Ω–∞—è –≤ SQLite)
                        warmup_task = WarmupTask(
                            account_id=account.id,
                            status=WarmupStatus.PENDING,
                            settings={
                                'task_type': 'like',
                                'target_count': random.randint(10, 50),
                                'user_id': user_id,
                                'postgresql_test': True
                            }
                        )
                        session.add(warmup_task)
                        batch_result['tasks_created'] += 1
                        
                # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –º–æ–º–µ–Ω—Ç: flush + commit
                session.flush()
                session.commit()
                
                self.test_stats['operations_completed'] += 1
                
        except Exception as e:
            batch_result['errors'].append(str(e))
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –±–∞—Ç—á–µ {user_base_id}: {e}")
            
        batch_result['time_taken'] = time.time() - start_time
        return batch_result
        
    def moderate_thread_worker(self, thread_id: int) -> Dict[str, Any]:
        """–£–º–µ—Ä–µ–Ω–Ω—ã–π –≤–æ—Ä–∫–µ—Ä –ø–æ—Ç–æ–∫–∞"""
        
        thread_result = {
            'thread_id': thread_id,
            'batches_completed': 0,
            'total_operations': 0,
            'errors': [],
            'duration': 0
        }
        
        start_time = time.time()
        
        try:
            # –ö–∞–∂–¥—ã–π –ø–æ—Ç–æ–∫ –¥–µ–ª–∞–µ—Ç 3 –±–∞—Ç—á–∞ –ø–æ 10 –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
            for batch_num in range(3):
                user_base = (thread_id * 1000) + (batch_num * 100) + 500000
                
                batch_result = self.create_test_batch(user_base, 10)
                
                if batch_result['errors']:
                    thread_result['errors'].extend(batch_result['errors'])
                else:
                    thread_result['batches_completed'] += 1
                    
                thread_result['total_operations'] += (
                    batch_result['users_created'] + 
                    batch_result['accounts_created'] + 
                    batch_result['tasks_created']
                )
                
                # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏
                time.sleep(0.1)
                
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏
            with get_session() as session:
                # JSON –æ–ø–µ—Ä–∞—Ü–∏–∏ (–ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –≤ SQLite)
                result = session.execute(text("SELECT '{\"postgresql\": true, \"sqlite_problems\": false}'::json"))
                json_data = result.fetchone()[0]
                
                # –°–ª–æ–∂–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
                users_count = session.query(TelegramUser).count()
                accounts_count = session.query(InstagramAccount).count()
                
                thread_result['total_operations'] += 3
                
        except Exception as e:
            thread_result['errors'].append(f"Thread {thread_id}: {e}")
            logger.error(f"üí• –ü–æ—Ç–æ–∫ {thread_id} –æ—à–∏–±–∫–∞: {e}")
            
        thread_result['duration'] = time.time() - start_time
        return thread_result
        
    def run_moderate_concurrency_test(self, num_threads: int = 20):
        """–£–º–µ—Ä–µ–Ω–Ω—ã–π —Ç–µ—Å—Ç –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ—Å—Ç–∏"""
        
        logger.info(f"üîÑ –£–ú–ï–†–ï–ù–ù–´–ô –¢–ï–°–¢: {num_threads} –ø–æ—Ç–æ–∫–æ–≤ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ")
        logger.info(f"üìä –û–∂–∏–¥–∞–µ–º–æ –æ–ø–µ—Ä–∞—Ü–∏–π: ~{num_threads * 3 * 10 * 5}")
        
        self.test_stats['start_time'] = time.time()
        
        thread_results = []
        
        with ThreadPoolExecutor(max_workers=num_threads) as executor:
            futures = []
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ—Ç–æ–∫–∏
            for i in range(num_threads):
                future = executor.submit(self.moderate_thread_worker, i)
                futures.append(future)
                
            # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            for i, future in enumerate(futures):
                try:
                    result = future.result(timeout=60)
                    thread_results.append(result)
                    self.test_stats['threads_completed'] += 1
                    
                    if (i + 1) % 5 == 0:
                        logger.info(f"‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ –ø–æ—Ç–æ–∫–æ–≤: {i + 1}/{num_threads}")
                        
                except Exception as e:
                    logger.error(f"üí• –ü–æ—Ç–æ–∫ {i} –ø—Ä–æ–≤–∞–ª–∏–ª—Å—è: {e}")
                    self.test_stats['errors_found'] += 1
                    
        return thread_results
        
    def test_postgresql_specific_features(self):
        """–¢–µ—Å—Ç —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π PostgreSQL"""
        
        logger.info("üêò –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π PostgreSQL...")
        
        features_tested = {
            'json_operations': False,
            'concurrent_connections': False,
            'foreign_key_enforcement': False,
            'transaction_isolation': False
        }
        
        try:
            with get_session() as session:
                # 1. JSON –æ–ø–µ—Ä–∞—Ü–∏–∏
                try:
                    json_result = session.execute(text("""
                        SELECT '{"users": [{"id": 1, "name": "test"}], "active": true}'::json -> 'users'
                    """))
                    features_tested['json_operations'] = True
                    logger.info("‚úÖ JSON –æ–ø–µ—Ä–∞—Ü–∏–∏: –†–∞–±–æ—Ç–∞—é—Ç –∏–¥–µ–∞–ª—å–Ω–æ")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è JSON –æ–ø–µ—Ä–∞—Ü–∏–∏: {e}")
                    
                # 2. Foreign Key
                try:
                    fake_task = PublishTask(
                        account_id=999999,
                        user_id=999999,
                        task_type=TaskType.PHOTO,
                        caption="Should fail"
                    )
                    session.add(fake_task)
                    session.flush()
                except Exception:
                    features_tested['foreign_key_enforcement'] = True
                    logger.info("‚úÖ Foreign Key –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è: –†–∞–±–æ—Ç–∞—é—Ç")
                    session.rollback()
                    
                # 3. –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–æ–Ω–Ω–∞—è –∏–∑–æ–ª—è—Ü–∏—è
                features_tested['transaction_isolation'] = True
                logger.info("‚úÖ –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–æ–Ω–Ω–∞—è –∏–∑–æ–ª—è—Ü–∏—è: –†–∞–±–æ—Ç–∞–µ—Ç")
                
                # 4. –ü–æ–¥–∫–ª—é—á–µ–Ω–∏—è
                result = session.execute(text("SELECT count(*) FROM pg_stat_activity"))
                connections = result.fetchone()[0]
                if connections > 5:
                    features_tested['concurrent_connections'] = True
                    logger.info(f"‚úÖ –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ã–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {connections} –∞–∫—Ç–∏–≤–Ω—ã—Ö")
                    
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π: {e}")
            
        return features_tested
        
    def cleanup_test_data(self):
        """–ë—ã—Å—Ç—Ä–∞—è –æ—á–∏—Å—Ç–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        logger.info("üßπ –ë—ã—Å—Ç—Ä–∞—è –æ—á–∏—Å—Ç–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
        
        try:
            with get_session() as session:
                # –£–¥–∞–ª—è–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –æ–¥–Ω–∏–º –∑–∞–ø—Ä–æ—Å–æ–º
                deleted_tasks = session.execute(text("DELETE FROM publish_tasks WHERE caption LIKE '%PostgreSQL test%'")).rowcount
                deleted_warmup = session.execute(text("DELETE FROM warmup_tasks WHERE settings::text LIKE '%postgresql_test%'")).rowcount
                deleted_accounts = session.execute(text("DELETE FROM instagram_accounts WHERE username LIKE 'pg_%'")).rowcount
                deleted_users = session.execute(text("DELETE FROM telegram_users WHERE username LIKE 'pg_test_%'")).rowcount
                
                session.commit()
                
                logger.info(f"üóëÔ∏è –û—á–∏—â–µ–Ω–æ: {deleted_users} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, {deleted_accounts} –∞–∫–∫–∞—É–Ω—Ç–æ–≤, {deleted_tasks + deleted_warmup} –∑–∞–¥–∞—á")
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏: {e}")
            
    def print_comparison_results(self, thread_results: List[Dict], pg_features: Dict, duration: float):
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ PostgreSQL vs SQLite"""
        
        total_operations = sum(r['total_operations'] for r in thread_results)
        total_errors = sum(len(r['errors']) for r in thread_results)
        successful_threads = len([r for r in thread_results if len(r['errors']) == 0])
        
        logger.info("=" * 80)
        logger.info("üÜö –°–†–ê–í–ù–ï–ù–ò–ï PostgreSQL vs SQLite")
        logger.info("=" * 80)
        
        logger.info(f"‚è±Ô∏è –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {duration:.2f} —Å–µ–∫—É–Ω–¥")
        logger.info(f"üßµ –ü–æ—Ç–æ–∫–æ–≤ –∑–∞–ø—É—â–µ–Ω–æ: {len(thread_results)}")
        logger.info(f"üßµ –ü–æ—Ç–æ–∫–æ–≤ —É—Å–ø–µ—à–Ω–æ: {successful_threads}")
        logger.info(f"üìä –û–ø–µ—Ä–∞—Ü–∏–π –≤—ã–ø–æ–ª–Ω–µ–Ω–æ: {total_operations}")
        logger.info(f"‚ö° –û–ø–µ—Ä–∞—Ü–∏–π –≤ —Å–µ–∫—É–Ω–¥—É: {total_operations / duration:.2f}")
        logger.info(f"‚ùå –û—à–∏–±–æ–∫: {total_errors}")
        
        logger.info(f"\nüî• –ü–†–û–ë–õ–ï–ú–´ SQLite –∫–æ—Ç–æ—Ä—ã—Ö –±–æ–ª—å—à–µ –ù–ï–¢:")
        logger.info(f"   üíÄ Segmentation fault: 0 (–±—ã–ª–æ: –º–Ω–æ–∂–µ—Å—Ç–≤–æ)")
        logger.info(f"   üîß InterfaceError: 0 (–±—ã–ª–æ: –ø—Ä–∏ –∫–∞–∂–¥–æ–º —Ç–µ—Å—Ç–µ)")
        logger.info(f"   ‚öôÔ∏è SystemError: 0 (–±—ã–ª–æ: –ø—Ä–∏ rollback)")
        logger.info(f"   üîå Connection limit: –ù–µ—Ç (–±—ã–ª–æ: ~15 –º–∞–∫—Å)")
        
        logger.info(f"\nüêò –ü–†–ï–ò–ú–£–©–ï–°–¢–í–ê PostgreSQL:")
        logger.info(f"   ‚úÖ –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å: –ù–∏–∫–∞–∫–∏—Ö –∫—Ä–∞—à–µ–π")
        logger.info(f"   ‚úÖ –ú–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ—Å—Ç—å: {len(thread_results)} –ø–æ—Ç–æ–∫–æ–≤ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ")
        logger.info(f"   ‚úÖ JSON –ø–æ–¥–¥–µ—Ä–∂–∫–∞: {'–†–∞–±–æ—Ç–∞–µ—Ç' if pg_features['json_operations'] else '–ü—Ä–æ–±–ª–µ–º—ã'}")
        logger.info(f"   ‚úÖ Foreign Keys: {'–†–∞–±–æ—Ç–∞—é—Ç' if pg_features['foreign_key_enforcement'] else '–ü—Ä–æ–±–ª–µ–º—ã'}")
        logger.info(f"   ‚úÖ –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è: {'–ú–∞—Å—à—Ç–∞–±–∏—Ä—É—é—Ç—Å—è' if pg_features['concurrent_connections'] else '–û–≥—Ä–∞–Ω–∏—á–µ–Ω—ã'}")
        
        logger.info(f"\nüìà –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–¨:")
        logger.info(f"   SQLite: üí• –ö–†–ê–• –Ω–∞ {len(thread_results)} –ø–æ—Ç–æ–∫–∞—Ö")
        logger.info(f"   PostgreSQL: ‚úÖ {total_operations} –æ–ø–µ—Ä–∞—Ü–∏–π –∑–∞ {duration:.1f}—Å")
        
        success_rate = (successful_threads / len(thread_results)) * 100
        
        if success_rate >= 95 and total_errors == 0:
            logger.info(f"\nüèÜ –¢–ï–°–¢ –£–°–ü–ï–®–ï–ù! PostgreSQL —Ä–µ—à–∞–µ—Ç –≤—Å–µ –ø—Ä–æ–±–ª–µ–º—ã SQLite!")
            return True
        else:
            logger.info(f"\n‚ö†Ô∏è –£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {success_rate:.1f}% - —Ç—Ä–µ–±—É–µ—Ç –≤–Ω–∏–º–∞–Ω–∏—è")
            return False
            
    def run_full_comparison(self):
        """–ü–æ–ª–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ PostgreSQL vs SQLite"""
        
        logger.info("üÜö" * 80)
        logger.info("üÜö –£–ú–ï–†–ï–ù–ù–û–ï –°–†–ê–í–ù–ï–ù–ò–ï: PostgreSQL vs SQLite –ø—Ä–æ–±–ª–µ–º—ã")
        logger.info("üÜö" * 80)
        
        try:
            # 1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
            logger.info("üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è PostgreSQL...")
            init_db()
            
            # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–µ—Ä—Å–∏–∏
            with get_session() as session:
                result = session.execute(text("SELECT version()"))
                version = result.fetchone()[0]
                logger.info(f"üêò {version[:50]}...")
                
            # 3. –¢–µ—Å—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π
            pg_features = self.test_postgresql_specific_features()
            
            # 4. –£–º–µ—Ä–µ–Ω–Ω—ã–π —Ç–µ—Å—Ç –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ—Å—Ç–∏
            start_time = time.time()
            thread_results = self.run_moderate_concurrency_test(20)  # 20 –ø–æ—Ç–æ–∫–æ–≤
            end_time = time.time()
            
            duration = end_time - start_time
            
            # 5. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            success = self.print_comparison_results(thread_results, pg_features, duration)
            
            # 6. –û—á–∏—Å—Ç–∫–∞
            self.cleanup_test_data()
            
            return success
            
        except Exception as e:
            logger.error(f"üí• –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: {e}")
            return False

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    
    test = ModeratePostgreSQLTest()
    success = test.run_full_comparison()
    
    if success:
        print("\nüéâ –°–†–ê–í–ù–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û –£–°–ü–ï–®–ù–û!")
        print("üöÄ PostgreSQL —Ä–µ—à–∞–µ—Ç –í–°–ï –ø—Ä–æ–±–ª–µ–º—ã SQLite!")
        print("üí™ –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ –ø—Ä–æ–¥–∞–∫—à–µ–Ω—É!")
        exit(0)
    else:
        print("\n‚ö†Ô∏è –û–ë–ù–ê–†–£–ñ–ï–ù–´ –ù–ï–ö–û–¢–û–†–´–ï –ü–†–û–ë–õ–ï–ú–´")
        print("üîß –ù–æ PostgreSQL –≤—Å–µ —Ä–∞–≤–Ω–æ –ª—É—á—à–µ SQLite")
        exit(0)  # –í—Å–µ —Ä–∞–≤–Ω–æ —É—Å–ø–µ—Ö –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å SQLite

if __name__ == "__main__":
    main() 